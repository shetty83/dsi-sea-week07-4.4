{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Welcome to the Futures Lesson!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are futures?\n",
    "\n",
    "Futures are small tasks that you want returned at a later time. They are asynchronous like threads, but have an extra layer of helper functions around them.\n",
    "\n",
    "Let's take a look at the following function..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n",
      "fin\n"
     ]
    }
   ],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from time import sleep\n",
    " \n",
    "def return_after_3_secs(message):\n",
    "    sleep(3)\n",
    "    return message\n",
    "\n",
    "# There are three threads here!\n",
    "pool = ThreadPoolExecutor(3)\n",
    " \n",
    "future = pool.submit(return_after_3_secs, ('fin'))\n",
    "print(future.done())\n",
    "sleep(3)\n",
    "print(future.done())\n",
    "print(future.result())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that as we query **```future.done()```**, we keep getting false! Well, obviously this is true, we haven't run our future yet! We can start our future with **```future.result()```**. This will attempt to run any query submitted to it with **```pool.submit()```**. Once our future is started we will have to wait 3 seconds to see it returned from the function because of the line **```sleep(3)```**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at our second example. The **```with```** statement loads all the threads into a new pool we are calling **```executor```**. The executor is assigned a future for each url and **```concurrent.futures.as_completed(future_to_url)```** cycles through those futures. **```data = future.result()```** takes the results of the futures so that we can print them out in our try except statment.\n",
    "\n",
    "If you are having trouble understanding how the **```with```** statement works, check out the explanation [here](http://preshing.com/20110920/the-python-with-statement-by-example/). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'http://www.cnn.com/' page is 130297 bytes\n",
      "'http://www.foxnews.com/' page is 70367 bytes\n",
      "'http://google.com/' page is 11519 bytes\n",
      "'http://www.bbc.co.uk/' page is 181448 bytes\n",
      "'http://europe.wsj.com/' page is 891076 bytes\n"
     ]
    }
   ],
   "source": [
    "import concurrent.futures\n",
    "import requests\n",
    "    \n",
    "URLS = ['http://www.foxnews.com/',\n",
    "        'http://www.cnn.com/',\n",
    "        'http://europe.wsj.com/',\n",
    "        'http://www.bbc.co.uk/',\n",
    "        'http://google.com/']\n",
    " \n",
    "# Retrieve a single page and report the url and contents\n",
    "def load_url(url):\n",
    "    response = requests.get(url)\n",
    "    return response.text\n",
    " \n",
    "# We can use a with statement to ensure threads are cleaned up promptly\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:\n",
    "    # Start the load operations and mark each future with its URL\n",
    "    future_to_url = {executor.submit(load_url, url): url for url in URLS}\n",
    "    for future in concurrent.futures.as_completed(future_to_url):\n",
    "        url = future_to_url[future]\n",
    "        try:\n",
    "            data = future.result()\n",
    "        except Exception as exc:\n",
    "            print('%r generated an exception: %s' % (url, exc))\n",
    "        else:\n",
    "            print('%r page is %d bytes' % (url, len(data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here's an example of the ProcessPoolExecutor()\n",
    "\n",
    "What do you think the advantages are of running multiple queries on different processes vs. different threads?\n",
    "What do you think the advantages are of using a ProcessPoolExecutor vs. ThreadPoolExecutor?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112272535095293 is prime: True\n",
      "112582705942171 is prime: True\n",
      "112272535095293 is prime: True\n",
      "115280095190773 is prime: True\n",
      "115797848077099 is prime: True\n",
      "1099726899285419 is prime: False\n"
     ]
    }
   ],
   "source": [
    "import concurrent.futures\n",
    "import math\n",
    " \n",
    "PRIMES = [\n",
    "    112272535095293,\n",
    "    112582705942171,\n",
    "    112272535095293,\n",
    "    115280095190773,\n",
    "    115797848077099,\n",
    "    1099726899285419]\n",
    " \n",
    "def is_prime(n):\n",
    "    if n % 2 == 0:\n",
    "        return False\n",
    " \n",
    "    sqrt_n = int(math.floor(math.sqrt(n)))\n",
    "    for i in range(3, sqrt_n + 1, 2):\n",
    "        if n % i == 0:\n",
    "            return False\n",
    "    return True\n",
    " \n",
    "def main():\n",
    "    with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "        for number, prime in zip(PRIMES, executor.map(is_prime, PRIMES)):\n",
    "            print('%d is prime: %s' % (number, prime))\n",
    " \n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why?\n",
    "\n",
    "You can obviously run the same exact code with a **```threadpoolexecutor```**, so why even bother? Well, threads stay inside the process that they are run in, while processes stay inside your kernel (Operating System). So while each process on your computer (iPython in this case) only has limited resources for each thread, multiple processes are able to draw from a much larger pool of resources. This comes with a price, as seperating your calculations into processes can slow down and even crash your kernel if they are not run correctly. In this way there is a trade off. Generally you will want to use threads until you absolutely have to upgrade to processes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## as_completed\n",
    "\n",
    "The next useful feature we are going to learn today is as_completed. This returns each future as they are completed! All you need to do is count up your threads to make sure they all come back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Return of 4\n",
      "Return of 1\n",
      "Return of 0\n",
      "Return of 2\n",
      "Return of 3\n"
     ]
    }
   ],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, wait, as_completed\n",
    "from time import sleep\n",
    "from random import randint\n",
    " \n",
    "def return_after_5_secs(num):\n",
    "    sleep(randint(1, 5))\n",
    "    return \"Return of {}\".format(num)\n",
    " \n",
    "pool = ThreadPoolExecutor(5)\n",
    "futures = []\n",
    "for x in range(5):\n",
    "    futures.append(pool.submit(return_after_5_secs, x))\n",
    " \n",
    "for x in as_completed(futures):\n",
    "    print(x.result())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map\n",
    "\n",
    "The last feature is the map function. The code below maps the values 0-9 to the function func. Try to use this function as much as possible. It will help you out immensely when you need to deal with large datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n"
     ]
    }
   ],
   "source": [
    "import concurrent.futures\n",
    "\n",
    "def func(num):\n",
    "    return num + 5\n",
    "\n",
    "with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "    results = executor.map(func, range(10))\n",
    "    for x in results:\n",
    "        print x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a final example I have included the imdb top 250 query done in futures. Try changing around the max workers and playing around with the Thread / Process Pools. Do you notice any difference in the speed with how things are returned? What are the tradeoffs of the different settings?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4%\n",
      "0.8%\n",
      "1.2%\n",
      "1.6%\n",
      "2.0%\n",
      "2.4%\n",
      "2.8%\n",
      "3.2%\n",
      "3.6%\n",
      "4.0%\n",
      "4.4%\n",
      "4.8%\n",
      "5.2%\n",
      "5.6%\n",
      "6.0%\n",
      "6.4%\n",
      "6.8%\n",
      "7.2%\n",
      "7.6%\n",
      "8.0%\n",
      "8.4%\n",
      "8.8%\n",
      "9.2%\n",
      "9.6%\n",
      "10.0%\n",
      "10.4%\n",
      "10.8%\n",
      "11.2%\n",
      "11.6%\n",
      "12.0%\n",
      "12.4%\n",
      "12.8%\n",
      "13.2%\n",
      "13.6%\n",
      "14.0%\n",
      "14.4%\n",
      "14.8%\n",
      "15.2%\n",
      "15.6%\n",
      "16.0%\n",
      "16.4%\n",
      "16.8%\n",
      "17.2%\n",
      "17.6%\n",
      "18.0%\n",
      "18.4%\n",
      "18.8%\n",
      "19.2%\n",
      "19.6%\n",
      "20.0%\n",
      "20.4%\n",
      "20.8%\n",
      "21.2%\n",
      "21.6%\n",
      "22.0%\n",
      "22.4%\n",
      "22.8%\n",
      "23.2%\n",
      "23.6%\n",
      "24.0%\n",
      "24.4%\n",
      "24.8%\n",
      "25.2%\n",
      "25.6%\n",
      "26.0%\n",
      "26.4%\n",
      "26.8%\n",
      "27.2%\n",
      "27.6%\n",
      "28.0%\n",
      "28.4%\n",
      "28.8%\n",
      "29.2%\n",
      "29.6%\n",
      "30.0%\n",
      "30.4%\n",
      "30.8%\n",
      "31.2%\n",
      "31.6%\n",
      "32.0%\n",
      "32.4%\n",
      "32.8%\n",
      "33.2%\n",
      "33.6%\n",
      "34.0%\n",
      "34.4%\n",
      "34.8%\n",
      "35.2%\n",
      "35.6%\n",
      "36.0%\n",
      "36.4%\n",
      "36.8%\n",
      "37.2%\n",
      "37.6%\n",
      "38.0%\n",
      "38.4%\n",
      "38.8%\n",
      "39.2%\n",
      "39.6%\n",
      "40.0%\n",
      "40.4%\n",
      "40.8%\n",
      "41.2%\n",
      "41.6%\n",
      "42.0%\n",
      "42.4%\n",
      "42.8%\n",
      "43.2%\n",
      "43.6%\n",
      "44.0%\n",
      "44.4%\n",
      "44.8%\n",
      "45.2%\n",
      "45.6%\n",
      "46.0%\n",
      "46.4%\n",
      "46.8%\n",
      "47.2%\n",
      "47.6%\n",
      "48.0%\n",
      "48.4%\n",
      "48.8%\n",
      "49.2%\n",
      "49.6%\n",
      "50.0%\n",
      "50.4%\n",
      "50.8%\n",
      "51.2%\n",
      "51.6%\n",
      "52.0%\n",
      "52.4%\n",
      "52.8%\n",
      "53.2%\n",
      "53.6%\n",
      "54.0%\n",
      "54.4%\n",
      "54.8%\n",
      "55.2%\n",
      "55.6%\n",
      "56.0%\n",
      "56.4%\n",
      "56.8%\n",
      "57.2%\n",
      "57.6%\n",
      "58.0%\n",
      "58.4%\n",
      "58.8%\n",
      "59.2%\n",
      "59.6%\n",
      "60.0%\n",
      "60.4%\n",
      "60.8%\n",
      "61.2%\n",
      "61.6%\n",
      "62.0%\n",
      "62.4%\n",
      "62.8%\n",
      "63.2%\n",
      "63.6%\n",
      "64.0%\n",
      "64.4%\n",
      "64.8%\n",
      "65.2%\n",
      "65.6%\n",
      "66.0%\n",
      "66.4%\n",
      "66.8%\n",
      "67.2%\n",
      "67.6%\n",
      "68.0%\n",
      "68.4%\n",
      "68.8%\n",
      "69.2%\n",
      "69.6%\n",
      "70.0%\n",
      "70.4%\n",
      "70.8%\n",
      "71.2%\n",
      "71.6%\n",
      "72.0%\n",
      "72.4%\n",
      "72.8%\n",
      "73.2%\n",
      "73.6%\n",
      "74.0%\n",
      "74.4%\n",
      "74.8%\n",
      "75.2%\n",
      "75.6%\n",
      "76.0%\n",
      "76.4%\n",
      "76.8%\n",
      "77.2%\n",
      "77.6%\n",
      "78.0%\n",
      "78.4%\n",
      "78.8%\n",
      "79.2%\n",
      "79.6%\n",
      "80.0%\n",
      "80.4%\n",
      "80.8%\n",
      "81.2%\n",
      "81.6%\n",
      "82.0%\n",
      "82.4%\n",
      "82.8%\n",
      "83.2%\n",
      "83.6%\n",
      "84.0%\n",
      "84.4%\n",
      "84.8%\n",
      "85.2%\n",
      "85.6%\n",
      "86.0%\n",
      "86.4%\n",
      "86.8%\n",
      "87.2%\n",
      "87.6%\n",
      "88.0%\n",
      "88.4%\n",
      "88.8%\n",
      "89.2%\n",
      "89.6%\n",
      "90.0%\n",
      "90.4%\n",
      "90.8%\n",
      "91.2%\n",
      "91.6%\n",
      "92.0%\n",
      "92.4%\n",
      "92.8%\n",
      "93.2%\n",
      "93.6%\n",
      "94.0%\n",
      "94.4%\n",
      "94.8%\n",
      "95.2%\n",
      "95.6%\n",
      "96.0%\n",
      "96.4%\n",
      "96.8%\n",
      "97.2%\n",
      "97.6%\n",
      "98.0%\n",
      "98.4%\n",
      "98.8%\n",
      "fin\n",
      "99.2%\n",
      "fin\n",
      "fin\n",
      "99.6%\n",
      "fin\n",
      "fin\n",
      "100.0%\n",
      "fin\n",
      "fin\n"
     ]
    }
   ],
   "source": [
    "import concurrent.futures\n",
    "import requests\n",
    "import re\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "def get_top_250():\n",
    "    response = requests.get('http://www.imdb.com/chart/top')\n",
    "    html = response.text\n",
    "    entries = re.findall(\"<a href.*?/title/(.*?)/\", html) #Wrong regex\n",
    "    return list(set(entries))\n",
    "\n",
    "def queryOMDB(id):\n",
    "    res = requests.get('http://www.omdbapi.com/?i='+id)\n",
    "    return {'id':id,'data':res.text,'type':'omdb'}\n",
    "\n",
    "def queryGross(id):\n",
    "    try:\n",
    "        res = requests.get('http://www.imdb.com/title/'+id)\n",
    "        gross_list = re.findall(\"Gross:</h4>[ ]*\\$([^ ]*)\", res.text)\n",
    "        gross = int(gross_list[0].replace(',', ''))\n",
    "        return {'id':id,'data':gross,'type':'gross'}\n",
    "    except Exception as ex:\n",
    "        return {'id':id,'data':'','type':'gross'}\n",
    "\n",
    "def checkAllDone(futures):\n",
    "    for x in futures:\n",
    "        if x.running():\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "executors_list = []\n",
    "pre_df = {}\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:\n",
    "    for url in get_top_250():\n",
    "        executors_list.append(executor.submit(queryOMDB, url))\n",
    "        executors_list.append(executor.submit(queryGross, url))\n",
    "    for future in executors_list:\n",
    "        try:\n",
    "            data = future.result()\n",
    "        except Exception as exc:\n",
    "            print('%r generated an exception: %s' % (url, exc))\n",
    "        else:\n",
    "            if not data['id'] in pre_df:\n",
    "                pre_df[data['id']] = {}\n",
    "                print str(100 * (len(pre_df.keys() * 2) / float(len(executors_list)))) + '%'\n",
    "            if data['type'] == 'gross':\n",
    "                pre_df[data['id']]['gross'] = data['data']\n",
    "            if data['type'] == 'omdb':\n",
    "                pre_df[data['id']]['omdb'] = data['data']\n",
    "            if checkAllDone(executors_list):\n",
    "                print 'fin'\n",
    "                new_df = pd.DataFrame(pre_df).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame Size:  500\n",
      "\n",
      "Sample id: \n",
      "tt0116231    1\n",
      "tt1375666    1\n",
      "tt0075686    1\n",
      "tt0078748    1\n",
      "tt0993846    1\n",
      "dtype: int64\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gross</th>\n",
       "      <th>omdb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tt0012349</th>\n",
       "      <td>2500000</td>\n",
       "      <td>{\"Title\":\"The Kid\",\"Year\":\"1921\",\"Rated\":\"NOT ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tt0015864</th>\n",
       "      <td></td>\n",
       "      <td>{\"Title\":\"The Gold Rush\",\"Year\":\"1925\",\"Rated\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tt0017136</th>\n",
       "      <td>26435</td>\n",
       "      <td>{\"Title\":\"Metropolis\",\"Year\":\"1927\",\"Rated\":\"N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tt0017925</th>\n",
       "      <td></td>\n",
       "      <td>{\"Title\":\"The General\",\"Year\":\"1926\",\"Rated\":\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tt0018455</th>\n",
       "      <td></td>\n",
       "      <td>{\"Title\":\"Sunrise\",\"Year\":\"1927\",\"Rated\":\"NOT ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             gross                                               omdb\n",
       "tt0012349  2500000  {\"Title\":\"The Kid\",\"Year\":\"1921\",\"Rated\":\"NOT ...\n",
       "tt0015864           {\"Title\":\"The Gold Rush\",\"Year\":\"1925\",\"Rated\"...\n",
       "tt0017136    26435  {\"Title\":\"Metropolis\",\"Year\":\"1927\",\"Rated\":\"N...\n",
       "tt0017925           {\"Title\":\"The General\",\"Year\":\"1926\",\"Rated\":\"...\n",
       "tt0018455           {\"Title\":\"Sunrise\",\"Year\":\"1927\",\"Rated\":\"NOT ..."
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Total amount of vals\n",
    "print \"DataFrame Size: \" , new_df.size\n",
    "print\n",
    "# Some sample ids\n",
    "print \"Sample id: \"\n",
    "print pd.Series(new_df.index.values).value_counts()[:5]\n",
    "print\n",
    "# The head\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
